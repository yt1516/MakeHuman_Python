import os
import cv2
import dlib
import numpy as np
import math

global np
global cv2
global dlib
global math


def txt_gen(img_name,detector,predictor):
    img = cv2.imread(img_name)
    gray=cv2.cvtColor(src=img,code=cv2.COLOR_BGR2GRAY)
    faces=detector(gray)
    pointsArray = [];

    for face in faces:
        x1 = face.left()
        y1 = face.top()
        x2 = face.right()
        y2 = face.bottom()

        landmarks=predictor(image=gray,box=face)

        for n in range(0,68):

            x=landmarks.part(n).x
            y=landmarks.part(n).y

#            cv2.circle(img=img, center=(x,y),radius=5,color=(0,255,0),thickness=-1)

            points = (int(x), int(y));

            pointsArray.append(points)
    return pointsArray


def readImages(filetitle):
    imagesArray = []
    for file in os.listdir():
        if file==filetitle:
            img = cv2.imread(filetitle)
            img = np.float32(img)/255.0
            imagesArray.append(img)
    return imagesArray

def readPoints(filetitle):
    pointsArray=[]
    for files in os.listdir():
        if files[0:9]==filetitle[0:9] and files.endswith('.txt'):
#             filetitle=files+'.txt'
            points = [];
            print(files)
            with open(files) as file :
                for line in file :
                    x, y = line.split()
                    points.append((int(x), int(y)))
            pointsArray.append(points)
    return pointsArray

def similarityTransform(inPoints, outPoints) :
    s60 = math.sin(60*math.pi/180);
    c60 = math.cos(60*math.pi/180);

    inPts = np.copy(inPoints).tolist();
    outPts = np.copy(outPoints).tolist();

    xin = c60*(inPts[0][0] - inPts[1][0]) - s60*(inPts[0][1] - inPts[1][1]) + inPts[1][0];
    yin = s60*(inPts[0][0] - inPts[1][0]) + c60*(inPts[0][1] - inPts[1][1]) + inPts[1][1];

    inPts.append([np.int(xin), np.int(yin)]);

    xout = c60*(outPts[0][0] - outPts[1][0]) - s60*(outPts[0][1] - outPts[1][1]) + outPts[1][0];
    yout = s60*(outPts[0][0] - outPts[1][0]) + c60*(outPts[0][1] - outPts[1][1]) + outPts[1][1];

    outPts.append([np.int(xout), np.int(yout)]);

    tform = cv2.estimateRigidTransform(np.array([inPts]), np.array([outPts]), False);

    return tform;

def draw_point(img, p, color ) :
    cv2.circle(img, p, 5, color, -1, cv2.LINE_AA, 0 )

def difference(point1,point2):
    import math
    (x1,y1)=point1
    (x2,y2)=point2
    log.debug(x1)
    return (math.sqrt((x2-x1)^2+(y2-y1)^2))

w=1500
h=1500

eyecornerDst = [(100, 450), (1400, 450)];

detector=dlib.get_frontal_face_detector()
predictor=dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")

MH_img='initial.png'
MH_landmarks=txt_gen(MH_img,detector,predictor)

Man_img='mwt.jpg'
Man_landmarks=txt_gen(Man_img,detector,predictor)

error_l=difference(MH_landmarks[0],Man_landmarks[0])

error_r=difference(MH_landmarks[16],Man_landmarks[16])

error_track=[]
error_track.append([error_l,error_r])

multiplier=1
step=0.01
count=1
while error_l >= 2 and error_r >= 2:
    
    G.app.modelCamera._horizontalRotation=0
    G.app.modelCamera._verticalInclination=0
    G.app.modelCamera.translation=[0,0.83+multiplier*step,0]
    G.app.modelCamera.zoomFactor=13+multiplier*step
    G.app.modelCamera._upY=0.2
    G.app.modelCamera._eyeX=0
    G.app.modelCamera._eyeZ=0
    MHScript.screenShot('initial.png')
    MH_img='initial.png'
    MH_landmarks=txt_gen(MH_img,detector,predictor)
    
    Man_img='mwt.jpg'
    Man_landmarks=txt_gen(Man_img,detector,predictor)
    
    error_l=difference(MH_landmarks[0],Man_landmarks[0])
    
    error_r=difference(MH_landmarks[16],Man_landmarks[16])

    [error_l_last,error_r_last]=error_track[count]

    if error_l >= error_l_last or error_r >= error_r_last:
        multiplier=-1
    
    count+=1